{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KKVdX_O7ZvY0"
   },
   "source": [
    "# PyNeuraLogic Introduction Example\n",
    "\n",
    "---\n",
    "\n",
    "This example will showcase how to define a GNN model in the PyNeuraLogic language and evaluate it. The example is self-contained, with everything that is required to be run in a Colab. It can also be run locally if the prerequisites are met (installed Java)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8CEE1Vy1Z5pQ"
   },
   "source": [
    "Install PyNeuraLogic from PyPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SujsflJQZ6Nj"
   },
   "outputs": [],
   "source": [
    "! pip install neuralogic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "flQw3rmscE7K"
   },
   "source": [
    "## Dataset\n",
    "\n",
    "We are going to use one of the predefined datasets called [Mutagenesis](https://www.doc.ic.ac.uk/~shm/mutagenesis.html). This dataset contains information about molecules that we are going to classify for mutagenicity on Salmonella typhimurium.\n",
    "\n",
    "Predefined datasets are located in `neuralogic.utils.data`, and by calling `Mutagenesis`, we retrieve a tuple containing the model (rules) and the input data (dataset). For this example, we are going to ignore the model and will define our own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "mglV4jndaL2B"
   },
   "outputs": [],
   "source": [
    "from neuralogic.utils.data import Mutagenesis\n",
    "\n",
    "\n",
    "_, dataset = Mutagenesis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gk8AIcCFasFV"
   },
   "source": [
    "Predefined examples are loaded from the file. We can check the first sample to get an idea how the data look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6VaRsqkIasaZ",
    "outputId": "e0c391ff-139e-4ead-8a5a-fe458f508580"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bond(d59_23, d59_5, 0), h(d59_23), c(d59_5), b_1(0), bond(d59_5, d59_23, 0), bond(d59_20, d59_19, 1), c(d59_20), c(d59_19), b_7(1), bond(d59_19, d59_20, 1), bond(d59_10, d59_3, 2), c(d59_10), c(d59_3), b_7(2), bond(d59_3, d59_10, 2), bond(d59_14, d59_10, 3), c(d59_14), b_7(3), bond(d59_10, d59_14, 3), bond(d59_4, d59_3, 4), c(d59_4), b_7(4), bond(d59_3, d59_4, 4), bond(d59_10, d59_9, 5), c(d59_9), b_7(5), bond(d59_9, d59_10, 5), bond(d59_15, d59_28, 6), c(d59_15), h(d59_28), b_1(6), bond(d59_28, d59_15, 6), bond(d59_12, d59_13, 7), c(d59_12), c(d59_13), b_7(7), bond(d59_13, d59_12, 7), bond(d59_8, d59_9, 8), c(d59_8), b_7(8), bond(d59_9, d59_8, 8), bond(d59_7, d59_25, 9), c(d59_7), h(d59_25), b_1(9), bond(d59_25, d59_7, 9), bond(d59_30, d59_17, 10), h(d59_30), c(d59_17), b_1(10), bond(d59_17, d59_30, 10), bond(d59_15, d59_12, 11), b_7(11), bond(d59_12, d59_15, 11), bond(d59_2, d59_1, 12), c(d59_2), c(d59_1), b_7(12), bond(d59_1, d59_2, 12), bond(d59_17, d59_16, 13), c(d59_16), b_7(13), bond(d59_16, d59_17, 13), bond(d59_31, d59_19, 14), h(d59_31), b_1(14), bond(d59_19, d59_31, 14), bond(d59_9, d59_11, 15), c(d59_11), b_7(15), bond(d59_11, d59_9, 15), bond(d59_3, d59_2, 16), b_7(16), bond(d59_2, d59_3, 16), bond(d59_27, d59_11, 17), h(d59_27), b_1(17), bond(d59_11, d59_27, 17), bond(d59_22, d59_4, 18), h(d59_22), b_1(18), bond(d59_4, d59_22, 18), bond(d59_7, d59_8, 19), b_7(19), bond(d59_8, d59_7, 19), bond(d59_24, d59_6, 20), h(d59_24), c(d59_6), b_1(20), bond(d59_6, d59_24, 20), bond(d59_15, d59_16, 21), b_7(21), bond(d59_16, d59_15, 21), bond(d59_7, d59_2, 22), b_7(22), bond(d59_2, d59_7, 22), bond(d59_18, d59_20, 23), c(d59_18), b_7(23), bond(d59_20, d59_18, 23), bond(d59_18, d59_17, 24), b_7(24), bond(d59_17, d59_18, 24), bond(d59_18, d59_13, 25), b_7(25), bond(d59_13, d59_18, 25), bond(d59_32, d59_33, 26), n(d59_32), o(d59_33), b_2(26), bond(d59_33, d59_32, 26), bond(d59_5, d59_6, 27), b_7(27), bond(d59_6, d59_5, 27), bond(d59_6, d59_1, 28), b_7(28), bond(d59_1, d59_6, 28), bond(d59_19, d59_14, 29), b_7(29), bond(d59_14, d59_19, 29), bond(d59_29, d59_16, 30), h(d59_29), b_1(30), bond(d59_16, d59_29, 30), bond(d59_11, d59_12, 31), b_7(31), bond(d59_12, d59_11, 31), bond(d59_14, d59_13, 32), b_7(32), bond(d59_13, d59_14, 32), bond(d59_26, d59_8, 33), h(d59_26), b_1(33), bond(d59_8, d59_26, 33), bond(d59_32, d59_34, 34), o(d59_34), b_2(34), bond(d59_34, d59_32, 34), bond(d59_32, d59_20, 35), b_1(35), bond(d59_20, d59_32, 35), bond(d59_1, d59_21, 36), h(d59_21), b_1(36), bond(d59_21, d59_1, 36), bond(d59_5, d59_4, 37), b_7(37), bond(d59_4, d59_5, 37).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(dataset.examples_file) as fp:\n",
    "    print(fp.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TLfOk69ublG9"
   },
   "source": [
    "This textual storage format is slightly different from the PyNeuraLogic language. To encode such samples directly in PyNeuraLogic (Python code), we would write:\n",
    "\n",
    "```\n",
    "Relation.bond(Term.d59_23, Term.d59_5, 0), Relation.h(Term.d59_23), ...\n",
    "```\n",
    "\n",
    "In this molecular example, we are essentially encoding heterogeneous graphs with edges called `bonds`, where the first two terms are the chemical atom ids, and the third term is the bond id. The atoms' ids are then associated with specific atom types, such as `h` for hydrogen. Bond ids are then associated with bond types, such as `b_1` for a single bond, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KOZev_cScMQy"
   },
   "source": [
    "## Template\n",
    "\n",
    "To define the template (model's 'architecture'), we first embed each chemical atom type to `atom_embed` with a unique learnable parameter vector of shape `[3, 1]` (an embedding). This can be simplified by utilizing list comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "vf-ryNvOcOYX"
   },
   "outputs": [],
   "source": [
    "from neuralogic.core import Template, R, V\n",
    "\n",
    "\n",
    "template = Template()\n",
    "\n",
    "template.add_rules([\n",
    "    (R.atom_embed(V.A)[3, 1] <= R.get(atom)(V.A)) for atom in [\"c\", \"o\", \"br\", \"i\", \"f\", \"h\", \"n\", \"cl\"]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qV58Qp-JcVlu"
   },
   "source": [
    "In the same way, we encode embeddings for bonds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "wuliEkxzcWZJ"
   },
   "outputs": [],
   "source": [
    "template.add_rules([\n",
    "    (R.bond_embed(V.B)[3, 1] <= R.get(bond)(V.B)) for bond in [\"b_1\", \"b_2\", \"b_3\", \"b_4\", \"b_5\", \"b_7\"]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yMI5Icgrccum"
   },
   "source": [
    "We add one rule ('layer'), which follows the message passing concept of GNNs. Particularly, it aggregates all neighbors `Y` (nodes connected by the bond relation) of the central node `X` and projects representations of `X` and `Y` from the previous layer (`atom_embed`) through learnable parameters of shape `[3, 3]`.  We then combine those projections together with bond embedding. We get a list of values for each neighbor `Y`, which are again combined into one tensor to serve as the output of the relation `layer_1` for node `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "YAGhZIy9cdcg"
   },
   "outputs": [],
   "source": [
    "template.add_rule(\n",
    "    R.layer_1(V.X) <= (R.atom_embed(V.X)[3, 3], R.atom_embed(V.Y)[3, 3], R.bond(V.X, V.Y, V.B), R.bond_embed(V.B)),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GA5ehjCNcnlu"
   },
   "source": [
    "In the same way, we add another two layers that will be 'connected' by utilizing representations from the previous layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "df_vNmbwcoIF"
   },
   "outputs": [],
   "source": [
    "template.add_rules([\n",
    "    R.layer_2(V.X) <= (R.layer_1(V.X)[3, 3], R.layer_1(V.Y)[3, 3], R.bond(V.X, V.Y, V.B), R.bond_embed(V.B)),\n",
    "    R.layer_3(V.X) <= (R.layer_2(V.X)[3, 3], R.layer_2(V.Y)[3, 3], R.bond(V.X, V.Y, V.B), R.bond_embed(V.B)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ZhNNrfrcuw7"
   },
   "source": [
    "In the last layer, we then aggregate all the nodes' (atoms') representations from the previous layer (`layer_3`), combine them, and project them through the learnable parameter of shape `[1, 3]` into a scalar value. This layer is then our output layer, corresponding to the learning target queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "K29q8NvLcvq4"
   },
   "outputs": [],
   "source": [
    "template.add_rule(\n",
    "    R.predict[1, 3] <= R.layer_3(V.X),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uju8LDYwcy2m"
   },
   "source": [
    "## Training\n",
    "\n",
    "When we have our dataset and template ready, it's time to build and train the model. We can do the training manually and write our own custom training loop, but we can also use predefined helpers - evaluators, that handle model building, training, dataset building, and more. Evaluators can be customized via `Settings`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "OvixrLnZc2Ao"
   },
   "outputs": [],
   "source": [
    "from neuralogic.core import Backend, Settings, Optimizer\n",
    "from neuralogic.nn.loss import MSE\n",
    "from neuralogic.nn import get_evaluator\n",
    "\n",
    "\n",
    "epochs = 120\n",
    "\n",
    "settings = Settings(optimizer=Optimizer.ADAM, epochs=epochs, learning_rate=0.001, error_function=MSE())\n",
    "evaluator = get_evaluator(template, Backend.JAVA, settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-AH9fwFddSn"
   },
   "source": [
    "We iterate through the iterator encapsulated in the `train` method for training, which yields a total loss of the epoch and the number of samples of the current epoch. We then get access to the results from the training loop that we can further visualize, inspect, log, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "sSVqIDvoddzV",
    "outputId": "9b4ed322-e895-4005-8f03-5e6486b159c7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "average_losses = []\n",
    "\n",
    "for current_total_loss, number_of_samples in evaluator.train(dataset):\n",
    "    clear_output(wait=True)\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "\n",
    "    plt.xlim(0, epochs)\n",
    "\n",
    "    average_losses.append(current_total_loss / number_of_samples)\n",
    "    \n",
    "    plt.plot(average_losses, label=\"Average loss\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.pause(0.001)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jl4xOLjP0vOG"
   },
   "source": [
    "We can also check what values would be the model outputs (for the same sample set here) by utilizing the `test` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OrRL7-wk0t_L",
    "outputId": "9f62a6ce-b29d-4d1a-947f-eb16f5d93683"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: 1.0, Predicted: 1 (0.7583636965102124)\n",
      "Expected: 1.0, Predicted: 1 (0.7323460491705178)\n",
      "Expected: 1.0, Predicted: 0 (0.2993995656765268)\n",
      "Expected: 1.0, Predicted: 1 (0.6554662345813814)\n",
      "Expected: 1.0, Predicted: 0 (0.13099011027294097)\n",
      "Expected: 1.0, Predicted: 1 (0.6804229750848236)\n",
      "Expected: 1.0, Predicted: 1 (0.6792529178246934)\n",
      "Expected: 1.0, Predicted: 1 (0.6146868397456817)\n",
      "Expected: 1.0, Predicted: 1 (0.5252482191581105)\n",
      "Expected: 1.0, Predicted: 0 (0.34682150586778443)\n",
      "Expected: 1.0, Predicted: 1 (0.615933840353385)\n",
      "Expected: 1.0, Predicted: 1 (0.5965356806120112)\n",
      "Expected: 1.0, Predicted: 1 (0.5387915562815375)\n",
      "Expected: 1.0, Predicted: 1 (0.5387286959102772)\n",
      "Expected: 1.0, Predicted: 1 (0.6551983541219301)\n",
      "Expected: 1.0, Predicted: 1 (0.5084267551621066)\n",
      "Expected: 1.0, Predicted: 1 (0.7043934398465992)\n",
      "Expected: 1.0, Predicted: 0 (0.2941796026638397)\n",
      "Expected: 1.0, Predicted: 1 (0.6347372581925238)\n",
      "Expected: 1.0, Predicted: 1 (0.6221022010644999)\n",
      "Expected: 1.0, Predicted: 1 (0.7583355733336016)\n",
      "Expected: 1.0, Predicted: 1 (0.6565214656810019)\n",
      "Expected: 1.0, Predicted: 1 (0.7035677211944709)\n",
      "Expected: 1.0, Predicted: 1 (0.6803899786005302)\n",
      "Expected: 1.0, Predicted: 1 (0.7043934398465992)\n",
      "Expected: 1.0, Predicted: 1 (0.6910626849834034)\n",
      "Expected: 1.0, Predicted: 1 (0.6948571992297221)\n",
      "Expected: 1.0, Predicted: 0 (0.23842970123280258)\n",
      "Expected: 1.0, Predicted: 0 (0.38868380585949414)\n",
      "Expected: 1.0, Predicted: 0 (0.4282341914117046)\n",
      "Expected: 1.0, Predicted: 1 (0.6632237535115572)\n",
      "Expected: 1.0, Predicted: 1 (0.7487758368547837)\n",
      "Expected: 1.0, Predicted: 1 (0.5396636421211021)\n",
      "Expected: 1.0, Predicted: 1 (0.6579722626080714)\n",
      "Expected: 1.0, Predicted: 1 (0.5739972113391792)\n",
      "Expected: 1.0, Predicted: 1 (0.7370474768683548)\n",
      "Expected: 1.0, Predicted: 1 (0.5725157368746513)\n",
      "Expected: 1.0, Predicted: 1 (0.7265495612512216)\n",
      "Expected: 1.0, Predicted: 1 (0.7078328792739843)\n",
      "Expected: 1.0, Predicted: 1 (0.706216401322436)\n",
      "Expected: 1.0, Predicted: 1 (0.6280954720243971)\n",
      "Expected: 1.0, Predicted: 1 (0.7362261063246508)\n",
      "Expected: 1.0, Predicted: 1 (0.7092773000133209)\n",
      "Expected: 1.0, Predicted: 1 (0.7583638391413665)\n",
      "Expected: 1.0, Predicted: 1 (0.7595384496297662)\n",
      "Expected: 1.0, Predicted: 1 (0.6317721401413431)\n",
      "Expected: 1.0, Predicted: 1 (0.6780562876284867)\n",
      "Expected: 1.0, Predicted: 1 (0.5619358766829866)\n",
      "Expected: 1.0, Predicted: 1 (0.7484304578839669)\n",
      "Expected: 1.0, Predicted: 1 (0.7583156943622809)\n",
      "Expected: 1.0, Predicted: 1 (0.5683013727888316)\n",
      "Expected: 1.0, Predicted: 0 (0.3512726702066945)\n",
      "Expected: 1.0, Predicted: 1 (0.7583408390407208)\n",
      "Expected: 1.0, Predicted: 1 (0.696469983914248)\n",
      "Expected: 1.0, Predicted: 1 (0.6166874036401182)\n",
      "Expected: 1.0, Predicted: 0 (0.23240191667792423)\n",
      "Expected: 1.0, Predicted: 0 (0.2082601082440419)\n",
      "Expected: 1.0, Predicted: 0 (0.30794475293748724)\n",
      "Expected: 1.0, Predicted: 1 (0.6298375342762591)\n",
      "Expected: 1.0, Predicted: 1 (0.6935770761489082)\n",
      "Expected: 1.0, Predicted: 1 (0.6695270822954716)\n",
      "Expected: 1.0, Predicted: 1 (0.5998270712309508)\n",
      "Expected: 1.0, Predicted: 1 (0.7323931956029396)\n",
      "Expected: 1.0, Predicted: 1 (0.7378390121450942)\n",
      "Expected: 1.0, Predicted: 1 (0.5646456978457701)\n",
      "Expected: 1.0, Predicted: 1 (0.6570108142241151)\n",
      "Expected: 1.0, Predicted: 1 (0.7323092667305957)\n",
      "Expected: 1.0, Predicted: 1 (0.7106720244560408)\n",
      "Expected: 1.0, Predicted: 1 (0.7371088758713855)\n",
      "Expected: 1.0, Predicted: 1 (0.7469464441806537)\n",
      "Expected: 1.0, Predicted: 1 (0.6388578643004411)\n",
      "Expected: 1.0, Predicted: 1 (0.6309335655472524)\n",
      "Expected: 1.0, Predicted: 0 (0.32012033424525477)\n",
      "Expected: 1.0, Predicted: 1 (0.5653142457065967)\n",
      "Expected: 1.0, Predicted: 1 (0.7726202188004274)\n",
      "Expected: 1.0, Predicted: 1 (0.7346236241719234)\n",
      "Expected: 1.0, Predicted: 1 (0.7583638613798231)\n",
      "Expected: 1.0, Predicted: 1 (0.7107040332247405)\n",
      "Expected: 1.0, Predicted: 1 (0.7043792844736534)\n",
      "Expected: 1.0, Predicted: 1 (0.5385396720062487)\n",
      "Expected: 1.0, Predicted: 1 (0.6631761516653099)\n",
      "Expected: 1.0, Predicted: 1 (0.6052898385913136)\n",
      "Expected: 1.0, Predicted: 0 (0.48409286566543563)\n",
      "Expected: 1.0, Predicted: 1 (0.6150692742488494)\n",
      "Expected: 1.0, Predicted: 1 (0.7583355733336016)\n",
      "Expected: 1.0, Predicted: 0 (0.39008091001712286)\n",
      "Expected: 1.0, Predicted: 1 (0.7106634742153302)\n",
      "Expected: 1.0, Predicted: 1 (0.6146377437898858)\n",
      "Expected: 1.0, Predicted: 1 (0.6298161378789255)\n",
      "Expected: 1.0, Predicted: 1 (0.6899058950768375)\n",
      "Expected: 1.0, Predicted: 1 (0.6143150108190001)\n",
      "Expected: 1.0, Predicted: 1 (0.7363267349211567)\n",
      "Expected: 1.0, Predicted: 1 (0.6964508039886993)\n",
      "Expected: 1.0, Predicted: 1 (0.6935770761489082)\n",
      "Expected: 1.0, Predicted: 1 (0.6968166575703288)\n",
      "Expected: 1.0, Predicted: 1 (0.748395312368955)\n",
      "Expected: 1.0, Predicted: 1 (0.6856451637592643)\n",
      "Expected: 1.0, Predicted: 0 (0.30367826613412136)\n",
      "Expected: 1.0, Predicted: 1 (0.7146829501369565)\n",
      "Expected: 1.0, Predicted: 1 (0.7323460491705182)\n",
      "Expected: 1.0, Predicted: 1 (0.6166385020720375)\n",
      "Expected: 1.0, Predicted: 1 (0.6547942460697398)\n",
      "Expected: 1.0, Predicted: 1 (0.7362679041621829)\n",
      "Expected: 1.0, Predicted: 1 (0.6173972274257867)\n",
      "Expected: 1.0, Predicted: 1 (0.6394355797619152)\n",
      "Expected: 1.0, Predicted: 1 (0.6563274617546493)\n",
      "Expected: 1.0, Predicted: 1 (0.7106634742153302)\n",
      "Expected: 1.0, Predicted: 1 (0.7495278563888776)\n",
      "Expected: 1.0, Predicted: 1 (0.5772950584306351)\n",
      "Expected: 1.0, Predicted: 1 (0.6933378293615585)\n",
      "Expected: 1.0, Predicted: 0 (0.299399565676527)\n",
      "Expected: 1.0, Predicted: 1 (0.7346515138444197)\n",
      "Expected: 1.0, Predicted: 1 (0.7317653971348662)\n",
      "Expected: 1.0, Predicted: 1 (0.6974586358304204)\n",
      "Expected: 1.0, Predicted: 1 (0.7092773000133209)\n",
      "Expected: 1.0, Predicted: 1 (0.6388066117393706)\n",
      "Expected: 1.0, Predicted: 1 (0.6973320743569688)\n",
      "Expected: 1.0, Predicted: 1 (0.7341213805364095)\n",
      "Expected: 1.0, Predicted: 1 (0.7583833829179949)\n",
      "Expected: 1.0, Predicted: 1 (0.5704908071457319)\n",
      "Expected: 1.0, Predicted: 1 (0.6967369269140754)\n",
      "Expected: 1.0, Predicted: 1 (0.67498905112343)\n",
      "Expected: 1.0, Predicted: 0 (0.2881288285891808)\n",
      "Expected: 1.0, Predicted: 1 (0.5341874556715155)\n",
      "Expected: 1.0, Predicted: 1 (0.6922953576801862)\n",
      "Expected: 0.0, Predicted: 0 (0.19958687745566916)\n",
      "Expected: 0.0, Predicted: 1 (0.6996803714662152)\n",
      "Expected: 0.0, Predicted: 0 (0.2358468967915116)\n",
      "Expected: 0.0, Predicted: 1 (0.5928737681403407)\n",
      "Expected: 0.0, Predicted: 0 (-0.030117110696054796)\n",
      "Expected: 0.0, Predicted: 0 (0.2425959789786388)\n",
      "Expected: 0.0, Predicted: 0 (0.005063434737414729)\n",
      "Expected: 0.0, Predicted: 1 (0.6525288304698175)\n",
      "Expected: 0.0, Predicted: 1 (0.5387312442276981)\n",
      "Expected: 0.0, Predicted: 0 (0.21817007145939663)\n",
      "Expected: 0.0, Predicted: 0 (0.29506769536756194)\n",
      "Expected: 0.0, Predicted: 0 (0.35847120534083726)\n",
      "Expected: 0.0, Predicted: 0 (0.23677664436858842)\n",
      "Expected: 0.0, Predicted: 0 (-0.3867813684490974)\n",
      "Expected: 0.0, Predicted: 1 (0.5400977395399515)\n",
      "Expected: 0.0, Predicted: 1 (0.7017010447225187)\n",
      "Expected: 0.0, Predicted: 0 (0.4815107501775932)\n",
      "Expected: 0.0, Predicted: 1 (0.540087079725364)\n",
      "Expected: 0.0, Predicted: 0 (0.04619192386374102)\n",
      "Expected: 0.0, Predicted: 0 (0.4340957816246011)\n",
      "Expected: 0.0, Predicted: 1 (0.614255689747763)\n",
      "Expected: 0.0, Predicted: 0 (0.16451232304835814)\n",
      "Expected: 0.0, Predicted: 1 (0.6391020761931864)\n",
      "Expected: 0.0, Predicted: 0 (-0.34741830124126594)\n",
      "Expected: 0.0, Predicted: 1 (0.5395255089006443)\n",
      "Expected: 0.0, Predicted: 0 (0.38866435300588353)\n",
      "Expected: 0.0, Predicted: 0 (-0.021700769916502393)\n",
      "Expected: 0.0, Predicted: 0 (0.23143101423668377)\n",
      "Expected: 0.0, Predicted: 1 (0.7024902087539399)\n",
      "Expected: 0.0, Predicted: 1 (0.5386683781006452)\n",
      "Expected: 0.0, Predicted: 0 (0.4601547218186083)\n",
      "Expected: 0.0, Predicted: 0 (0.45923010398655006)\n",
      "Expected: 0.0, Predicted: 1 (0.6156376094970306)\n",
      "Expected: 0.0, Predicted: 0 (0.47715802962277315)\n",
      "Expected: 0.0, Predicted: 1 (0.540157926316519)\n",
      "Expected: 0.0, Predicted: 0 (0.25699755640628924)\n",
      "Expected: 0.0, Predicted: 0 (0.15934963377074265)\n",
      "Expected: 0.0, Predicted: 1 (0.5695116871366503)\n",
      "Expected: 0.0, Predicted: 1 (0.610120002737434)\n",
      "Expected: 0.0, Predicted: 0 (0.4583170758695513)\n",
      "Expected: 0.0, Predicted: 0 (-0.013248018643897581)\n",
      "Expected: 0.0, Predicted: 0 (0.23219307923905688)\n",
      "Expected: 0.0, Predicted: 0 (0.10577317326637647)\n",
      "Expected: 0.0, Predicted: 1 (0.7139261186694634)\n",
      "Expected: 0.0, Predicted: 0 (0.16307910494712463)\n",
      "Expected: 0.0, Predicted: 1 (0.6933140231457103)\n",
      "Expected: 0.0, Predicted: 0 (0.23143326603831682)\n",
      "Expected: 0.0, Predicted: 0 (-0.02048293603376172)\n",
      "Expected: 0.0, Predicted: 1 (0.5184243349321059)\n",
      "Expected: 0.0, Predicted: 0 (0.09390755503331506)\n",
      "Expected: 0.0, Predicted: 0 (0.38921210100714004)\n",
      "Expected: 0.0, Predicted: 0 (0.10220759833787267)\n",
      "Expected: 0.0, Predicted: 0 (0.2985559912293818)\n",
      "Expected: 0.0, Predicted: 1 (0.5452199443012442)\n",
      "Expected: 0.0, Predicted: 0 (0.42895497205342853)\n",
      "Expected: 0.0, Predicted: 1 (0.5836976592397762)\n",
      "Expected: 0.0, Predicted: 1 (0.7116091612132139)\n",
      "Expected: 0.0, Predicted: 0 (0.23282191081185483)\n",
      "Expected: 0.0, Predicted: 1 (0.6996193591425841)\n",
      "Expected: 0.0, Predicted: 1 (0.610881240229634)\n",
      "Expected: 0.0, Predicted: 0 (-0.1936151522273555)\n",
      "Expected: 0.0, Predicted: 1 (0.7127802072815519)\n",
      "Expected: 0.0, Predicted: 0 (0.27876966722315244)\n"
     ]
    }
   ],
   "source": [
    "for y, y_hat in evaluator.test(dataset):\n",
    "    print(f\"Expected: {y}, Predicted: {round(y_hat)} ({y_hat})\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Mutagenesis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
